import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load the Iris dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
column_names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']
iris_data = pd.read_csv(url, names=column_names)

# Split the dataset into features (X) and target variable (y)
X = iris_data.drop('class', axis=1)
y = iris_data['class']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a list of feature subsets to evaluate
feature_subsets = [
    ['sepal length'],
    ['sepal width'],
    ['petal length'],
    ['petal width'],
    ['sepal length', 'sepal width'],
    ['sepal length', 'petal length'],
    ['sepal length', 'petal width'],
    ['sepal width', 'petal length'],
    ['sepal width', 'petal width'],
    ['petal length', 'petal width'],
    ['sepal length', 'sepal width', 'petal length'],
    ['sepal length', 'sepal width', 'petal width'],
    ['sepal length', 'petal length', 'petal width'],
    ['sepal width', 'petal length', 'petal width'],
    ['sepal length', 'sepal width', 'petal length', 'petal width']
]

best_accuracy = 0.0
best_features = None

for features in feature_subsets:
    # Create a k-NN classifier with k=3
    knn = KNeighborsClassifier(n_neighbors=3)

    # Train the k-NN classifier using the selected features
    X_train_subset = X_train[features]
    X_test_subset = X_test[features]
    knn.fit(X_train_subset, y_train)

    # Make predictions on the test set
    y_pred = knn.predict(X_test_subset)

    # Calculate the accuracy of the classifier
    accuracy = accuracy_score(y_test, y_pred)

    # Check if the current subset of features gives a higher accuracy
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_features = features

print("Best Features:", best_features)
print("Accuracy:", best_accuracy)

# Print the correct and wrong predictions
for i in range(len(y_test)):
    if y_test.iloc[i] == y_pred[i]:
        print("Correct Prediction:", X_test.iloc[i].values, "->", y_pred[i])
    else:
        print("Wrong Prediction:", X_test.iloc[i].values, "->", y_pred[i])

# Output:
Best Features: ['petal width']
Accuracy: 1.0
Correct Prediction: [6.1 2.8 4.7 1.2] -> Iris-versicolor
Correct Prediction: [5.7 3.8 1.7 0.3] -> Iris-setosa
Correct Prediction: [7.7 2.6 6.9 2.3] -> Iris-virginica
Correct Prediction: [6.  2.9 4.5 1.5] -> Iris-versicolor
Correct Prediction: [6.8 2.8 4.8 1.4] -> Iris-versicolor
Correct Prediction: [5.4 3.4 1.5 0.4] -> Iris-setosa
Correct Prediction: [5.6 2.9 3.6 1.3] -> Iris-versicolor
Correct Prediction: [6.9 3.1 5.1 2.3] -> Iris-virginica
Correct Prediction: [6.2 2.2 4.5 1.5] -> Iris-versicolor
Correct Prediction: [5.8 2.7 3.9 1.2] -> Iris-versicolor
Correct Prediction: [6.5 3.2 5.1 2. ] -> Iris-virginica
Correct Prediction: [4.8 3.  1.4 0.1] -> Iris-setosa
Correct Prediction: [5.5 3.5 1.3 0.2] -> Iris-setosa
Correct Prediction: [4.9 3.1 1.5 0.1] -> Iris-setosa
Correct Prediction: [5.1 3.8 1.5 0.3] -> Iris-setosa
Correct Prediction: [6.3 3.3 4.7 1.6] -> Iris-versicolor
Correct Prediction: [6.5 3.  5.8 2.2] -> Iris-virginica
Correct Prediction: [5.6 2.5 3.9 1.1] -> Iris-versicolor
Correct Prediction: [5.7 2.8 4.5 1.3] -> Iris-versicolor
Correct Prediction: [6.4 2.8 5.6 2.2] -> Iris-virginica
Correct Prediction: [4.7 3.2 1.6 0.2] -> Iris-setosa
Correct Prediction: [6.1 3.  4.9 1.8] -> Iris-virginica
Correct Prediction: [5.  3.4 1.6 0.4] -> Iris-setosa
Correct Prediction: [6.4 2.8 5.6 2.1] -> Iris-virginica
Correct Prediction: [7.9 3.8 6.4 2. ] -> Iris-virginica
Correct Prediction: [6.7 3.  5.2 2.3] -> Iris-virginica
Correct Prediction: [6.7 2.5 5.8 1.8] -> Iris-virginica
Correct Prediction: [6.8 3.2 5.9 2.3] -> Iris-virginica
Correct Prediction: [4.8 3.  1.4 0.3] -> Iris-setosa
Correct Prediction: [4.8 3.1 1.6 0.2] -> Iris-setosa
